{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-06T12:52:46.614372Z","iopub.execute_input":"2022-01-06T12:52:46.614728Z","iopub.status.idle":"2022-01-06T12:52:46.642181Z","shell.execute_reply.started":"2022-01-06T12:52:46.614648Z","shell.execute_reply":"2022-01-06T12:52:46.64157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <h1 style='background:#C2C4E2; border:0; color:black'><center>DROWSINESS DETECTION</center></h1> ","metadata":{}},{"cell_type":"markdown","source":"   <a id='top'></a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 style='background:#C2C4E2; border:0; color:black'><center>TABLE OF CONTENTS</center></h1>\n\n[1. IMPORTING LIBRARIES](#1)\n    \n[2. LOADING DATA](#2)    \n\n[3. DATA VISUALIZATION AND CLEANINGS](#3)     \n\n[4. DATA PREPROCESSING](#4)     \n\n[5. MODEL BUILDING](#5) \n\n[6. CONCLUSION](#6) \n\n[7. END](#7) ","metadata":{}},{"cell_type":"markdown","source":" <a id=\"1\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>IMPORTING LIBRARIES</center></h1>","metadata":{"execution":{"iopub.status.busy":"2021-12-20T07:11:06.693287Z","iopub.execute_input":"2021-12-20T07:11:06.694435Z","iopub.status.idle":"2021-12-20T07:11:06.700106Z","shell.execute_reply.started":"2021-12-20T07:11:06.694361Z","shell.execute_reply":"2021-12-20T07:11:06.69914Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input, Lambda, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nimport os\nimport cv2\n\n%matplotlib inline\nprint(\"Tensorflow version : \", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:46.644831Z","iopub.execute_input":"2022-01-06T12:52:46.645221Z","iopub.status.idle":"2022-01-06T12:52:52.68043Z","shell.execute_reply.started":"2022-01-06T12:52:46.64518Z","shell.execute_reply":"2022-01-06T12:52:52.679684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"2\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>LOADING DATA</center></h1>","metadata":{}},{"cell_type":"markdown","source":"## CHECK LABELS","metadata":{"execution":{"iopub.status.busy":"2021-12-20T07:14:37.945231Z","iopub.execute_input":"2021-12-20T07:14:37.945774Z","iopub.status.idle":"2021-12-20T07:14:37.951529Z","shell.execute_reply.started":"2021-12-20T07:14:37.945717Z","shell.execute_reply":"2021-12-20T07:14:37.950291Z"}}},{"cell_type":"code","source":"labels = os.listdir(\"../input/drowsiness-dataset/train\")\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:52.682113Z","iopub.execute_input":"2022-01-06T12:52:52.682517Z","iopub.status.idle":"2022-01-06T12:52:52.708783Z","shell.execute_reply.started":"2022-01-06T12:52:52.682479Z","shell.execute_reply":"2022-01-06T12:52:52.707936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VISUALIZE SOME IMAGES","metadata":{}},{"cell_type":"code","source":"# Visualize a closed eye from the dataset\nplt.imshow(plt.imread(\"../input/drowsiness-dataset/train/Closed/_0.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:52.709923Z","iopub.execute_input":"2022-01-06T12:52:52.710595Z","iopub.status.idle":"2022-01-06T12:52:52.998101Z","shell.execute_reply.started":"2022-01-06T12:52:52.710554Z","shell.execute_reply":"2022-01-06T12:52:52.997382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize an open eye from the given dataset\nplt.imshow(plt.imread(\"../input/drowsiness-dataset/train/Open/_0.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:53.000199Z","iopub.execute_input":"2022-01-06T12:52:53.000625Z","iopub.status.idle":"2022-01-06T12:52:53.25055Z","shell.execute_reply.started":"2022-01-06T12:52:53.000585Z","shell.execute_reply":"2022-01-06T12:52:53.249861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the image array","metadata":{}},{"cell_type":"code","source":"a = plt.imread(\"../input/drowsiness-dataset/train/yawn/10.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:53.251438Z","iopub.execute_input":"2022-01-06T12:52:53.251622Z","iopub.status.idle":"2022-01-06T12:52:53.276161Z","shell.execute_reply.started":"2022-01-06T12:52:53.251597Z","shell.execute_reply":"2022-01-06T12:52:53.275526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check a.shape\na.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:53.277434Z","iopub.execute_input":"2022-01-06T12:52:53.277683Z","iopub.status.idle":"2022-01-06T12:52:53.283622Z","shell.execute_reply.started":"2022-01-06T12:52:53.277647Z","shell.execute_reply":"2022-01-06T12:52:53.282625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize yawn image","metadata":{}},{"cell_type":"code","source":"plt.imshow(plt.imread(\"../input/drowsiness-dataset/train/yawn/10.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:53.285175Z","iopub.execute_input":"2022-01-06T12:52:53.285427Z","iopub.status.idle":"2022-01-06T12:52:53.549491Z","shell.execute_reply.started":"2022-01-06T12:52:53.285393Z","shell.execute_reply":"2022-01-06T12:52:53.5488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we do not need the background, as it is unnecessary.\nWe only need the face image array.","metadata":{}},{"cell_type":"markdown","source":"## For 'yawn' and 'not_yawn', consider only the face (and not the background)","metadata":{}},{"cell_type":"code","source":"def face_for_yawn(direc=\"../input/drowsiness-dataset/train\", face_cas_path=\"../input/prediction-images/haarcascade_frontalface_default.xml\"):\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n            face_cascade = cv2.CascadeClassifier(face_cas_path)\n            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n            for (x, y, w, h) in faces:\n                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                roi_color = img[y:y+h, x:x+w]\n                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n                yaw_no.append([resized_array, class_num1])\n    return yaw_no\n\n\nyawn_no_yawn = face_for_yawn()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:52:53.551091Z","iopub.execute_input":"2022-01-06T12:52:53.55157Z","iopub.status.idle":"2022-01-06T12:55:05.577626Z","shell.execute_reply.started":"2022-01-06T12:52:53.551534Z","shell.execute_reply":"2022-01-06T12:55:05.576845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For 'Open' and 'Closed' eyes","metadata":{}},{"cell_type":"code","source":"def get_data(dir_path=\"../input/drowsiness-dataset/train/\", face_cas=\"../input/prediction-images/haarcascade_frontalface_default.xml\", eye_cas=\"../input/prediction-images/haarcascade.xml\"):\n    labels = ['Closed', 'Open']\n    IMG_SIZE = 145\n    data = []\n    for label in labels:\n        path = os.path.join(dir_path, label)\n        class_num = labels.index(label)\n        class_num +=2\n        print(class_num)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([resized_array, class_num])\n            except Exception as e:\n                print(e)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:55:05.579138Z","iopub.execute_input":"2022-01-06T12:55:05.579381Z","iopub.status.idle":"2022-01-06T12:55:05.586162Z","shell.execute_reply.started":"2022-01-06T12:55:05.579349Z","shell.execute_reply":"2022-01-06T12:55:05.58537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = get_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:55:05.589865Z","iopub.execute_input":"2022-01-06T12:55:05.590425Z","iopub.status.idle":"2022-01-06T12:55:18.654138Z","shell.execute_reply.started":"2022-01-06T12:55:05.590387Z","shell.execute_reply":"2022-01-06T12:55:18.653387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extend data and convert array","metadata":{}},{"cell_type":"code","source":"def append_data():\n    yaw_no = face_for_yawn()\n    data = get_data()\n    yaw_no.extend(data)\n    return np.array(yaw_no)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:55:18.655366Z","iopub.execute_input":"2022-01-06T12:55:18.655614Z","iopub.status.idle":"2022-01-06T12:55:18.661292Z","shell.execute_reply.started":"2022-01-06T12:55:18.655582Z","shell.execute_reply":"2022-01-06T12:55:18.660505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Store data in a new variable","metadata":{}},{"cell_type":"code","source":"new_data = append_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:55:18.66369Z","iopub.execute_input":"2022-01-06T12:55:18.664235Z","iopub.status.idle":"2022-01-06T12:57:18.081903Z","shell.execute_reply.started":"2022-01-06T12:55:18.664199Z","shell.execute_reply":"2022-01-06T12:57:18.080069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seperate labels and features\nX = []\ny = []\nfor feature, label in new_data:\n    X.append(feature)\n    y.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.083493Z","iopub.execute_input":"2022-01-06T12:57:18.083761Z","iopub.status.idle":"2022-01-06T12:57:18.091728Z","shell.execute_reply.started":"2022-01-06T12:57:18.083725Z","shell.execute_reply":"2022-01-06T12:57:18.090887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reshape the array","metadata":{}},{"cell_type":"code","source":"X = np.array(X)\nX = X.reshape(-1,145,145,3)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.093648Z","iopub.execute_input":"2022-01-06T12:57:18.093909Z","iopub.status.idle":"2022-01-06T12:57:18.14487Z","shell.execute_reply.started":"2022-01-06T12:57:18.093875Z","shell.execute_reply":"2022-01-06T12:57:18.144069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Binarizer","metadata":{}},{"cell_type":"code","source":"label_bin = LabelBinarizer()\ny = label_bin.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.146057Z","iopub.execute_input":"2022-01-06T12:57:18.147899Z","iopub.status.idle":"2022-01-06T12:57:18.158447Z","shell.execute_reply.started":"2022-01-06T12:57:18.147867Z","shell.execute_reply":"2022-01-06T12:57:18.15755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label array","metadata":{}},{"cell_type":"code","source":"y = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.159575Z","iopub.execute_input":"2022-01-06T12:57:18.159887Z","iopub.status.idle":"2022-01-06T12:57:18.16429Z","shell.execute_reply.started":"2022-01-06T12:57:18.159852Z","shell.execute_reply":"2022-01-06T12:57:18.163432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split the data into training and testing data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.165909Z","iopub.execute_input":"2022-01-06T12:57:18.166207Z","iopub.status.idle":"2022-01-06T12:57:18.212226Z","shell.execute_reply.started":"2022-01-06T12:57:18.166173Z","shell.execute_reply":"2022-01-06T12:57:18.211449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_generator = ImageDataGenerator(rescale = 1/255, zoom_range = 0.2, horizontal_flip = True, rotation_range = 30)\ntest_generator = ImageDataGenerator(rescale = 1/255)\n\ntrain_generator = train_generator.flow(np.array(X_train), y_train, shuffle = False)\ntest_generator = test_generator.flow(np.array(X_test), y_test, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.213651Z","iopub.execute_input":"2022-01-06T12:57:18.213905Z","iopub.status.idle":"2022-01-06T12:57:18.382713Z","shell.execute_reply.started":"2022-01-06T12:57:18.213871Z","shell.execute_reply":"2022-01-06T12:57:18.381985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"3\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>BUILDING MODEL</center></h1>","metadata":{"execution":{"iopub.status.busy":"2021-12-20T07:50:55.133146Z","iopub.execute_input":"2021-12-20T07:50:55.133386Z","iopub.status.idle":"2021-12-20T07:50:55.138741Z","shell.execute_reply.started":"2021-12-20T07:50:55.133359Z","shell.execute_reply":"2021-12-20T07:50:55.137556Z"}}},{"cell_type":"markdown","source":"## Build the model","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(256, (3,3), activation = 'relu', input_shape = X_train.shape[1:]),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(128, (3,3), activation = 'relu'),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(64, (3,3), activation = 'relu'),\n    MaxPooling2D(pool_size = (2,2)),\n    Conv2D(32, (3,3), activation = 'relu'),\n    MaxPooling2D(pool_size = (2,2)),\n    Flatten(),\n    Dropout(0.5),\n    Dense(64, activation = 'relu'),\n    Dense(4, activation = 'softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:18.384193Z","iopub.execute_input":"2022-01-06T12:57:18.384452Z","iopub.status.idle":"2022-01-06T12:57:20.763513Z","shell.execute_reply.started":"2022-01-06T12:57:18.384417Z","shell.execute_reply":"2022-01-06T12:57:20.761743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile the model","metadata":{}},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',\n             optimizer = 'adam',\n             metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:20.764728Z","iopub.execute_input":"2022-01-06T12:57:20.764959Z","iopub.status.idle":"2022-01-06T12:57:20.77745Z","shell.execute_reply.started":"2022-01-06T12:57:20.764926Z","shell.execute_reply":"2022-01-06T12:57:20.776649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the summary of the model","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:20.778869Z","iopub.execute_input":"2022-01-06T12:57:20.779678Z","iopub.status.idle":"2022-01-06T12:57:20.791703Z","shell.execute_reply.started":"2022-01-06T12:57:20.779642Z","shell.execute_reply":"2022-01-06T12:57:20.791063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fit the model","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_generator, epochs = 50, validation_data = test_generator, shuffle = True, validation_steps = len(test_generator))","metadata":{"execution":{"iopub.status.busy":"2022-01-06T12:57:20.792907Z","iopub.execute_input":"2022-01-06T12:57:20.793476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"4\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>EVALUATE THE MODEL</center></h1>","metadata":{}},{"cell_type":"markdown","source":"## Check the history","metadata":{}},{"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label = 'training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label = 'validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, 'b', label = 'training loss')\nplt.plot(epochs, val_loss, 'r', label = 'validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"model.save(\"drowiness_new6.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make predictions","metadata":{}},{"cell_type":"code","source":"prediction = model.predict(X_test) \nprediction = np.argmax(prediction,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the predictions\nprediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification report","metadata":{}},{"cell_type":"code","source":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(np.argmax(y_test, axis = 1), prediction, target_names = labels_new))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"5\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>PREDICTION FUNCTION</center></h1>","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:16:47.126881Z","iopub.execute_input":"2021-12-20T08:16:47.127128Z","iopub.status.idle":"2021-12-20T08:16:47.132031Z","shell.execute_reply.started":"2021-12-20T08:16:47.1271Z","shell.execute_reply":"2021-12-20T08:16:47.131167Z"}}},{"cell_type":"code","source":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\nIMG_SIZE = 145\ndef prepare(filepath, face_cas=\"../input/prediction-images/haarcascade_frontalface_default.xml\"):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array / 255\n    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nmodel = tf.keras.models.load_model(\"./drowiness_new6.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 0 : YAWN\n- 1 : NO YAWN\n- 2 : CLOSED\n- 3 : OPEN","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:18:34.989927Z","iopub.execute_input":"2021-12-20T08:18:34.990175Z","iopub.status.idle":"2021-12-20T08:18:34.994808Z","shell.execute_reply.started":"2021-12-20T08:18:34.990147Z","shell.execute_reply":"2021-12-20T08:18:34.993841Z"}}},{"cell_type":"code","source":"# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\nprediction = model.predict([prepare(\"../input/drowsiness-dataset/train/no_yawn/1067.jpg\")])\nnp.argmax(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\nprediction = model.predict([prepare(\"../input/drowsiness-dataset/train/yawn/13.jpg\")])\nnp.argmax(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\nprediction = model.predict([prepare(\"../input/drowsiness-dataset/train/Closed/_101.jpg\")])\nnp.argmax(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\nprediction = model.predict([prepare(\"../input/drowsiness-dataset/train/Open/_104.jpg\")])\nnp.argmax(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <a id=\"6\"></a>\n<h1 style='background:#C2C4E2; border:0; color:black'><center>FIN</center></h1>","metadata":{"execution":{"iopub.status.busy":"2021-12-20T08:25:15.594264Z","iopub.execute_input":"2021-12-20T08:25:15.594956Z","iopub.status.idle":"2021-12-20T08:25:15.599561Z","shell.execute_reply.started":"2021-12-20T08:25:15.594921Z","shell.execute_reply":"2021-12-20T08:25:15.598456Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}